[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Vincenzo Palazeti",
    "section": "",
    "text": "My name is Vincenzo Palazeti, but everyone calls me Vinnie.\nI am a Data Scientist at Vevo. My main focus thus far has been forecasting various quantities. Inventory, Views, Watch Time, Revenue, etc.\nPrior to Vevo, I worked for several startups in the Sports & Horse wagering industries. Some of the topics I’ve spent time on are yield optimization, ensembling methods, ranking algorthims, timeseries, experimental methods, & data engineering."
  },
  {
    "objectID": "about.html#hello",
    "href": "about.html#hello",
    "title": "Vincenzo Palazeti",
    "section": "",
    "text": "My name is Vincenzo Palazeti, but everyone calls me Vinnie.\nI am a Data Scientist at Vevo. My main focus thus far has been forecasting various quantities. Inventory, Views, Watch Time, Revenue, etc.\nPrior to Vevo, I worked for several startups in the Sports & Horse wagering industries. Some of the topics I’ve spent time on are yield optimization, ensembling methods, ranking algorthims, timeseries, experimental methods, & data engineering."
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Vincenzo Palazeti",
    "section": "Experience",
    "text": "Experience\n\n\n Data Scientist, 2023-Present\n\n\nVevo\n\n\n Data Scientist, 2022-2023\n\n\nAlphaPeak\n\n\n Data Scientist, 2020-2022\n\n\nSports Betting Innovative Analytics\n\n\n Statistician, 2019-2020\n\n\nCenter for Criminal Justice Research"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Vincenzo Palazeti",
    "section": "Education",
    "text": "Education\n\n\n MS in Applied Statistics, 2020\n\n\nUniversity of Loyola Chicago\n\n\n BS in Professional Selling, 2017\n\n\nBall State University"
  },
  {
    "objectID": "posts/pandas/index.html",
    "href": "posts/pandas/index.html",
    "title": "pandas",
    "section": "",
    "text": "Grab all of the month names\nmonths = pd.date_range('2020-01-01','2020-12-31',freq='MS').map(lambda x: x.month_name())\npandas types to redshift schema\ncols = d.dtypes\nl = {'object':'varchar(255)', 'int64':'bigint','float64':'double precision','datetime64[ns]':'date'}\ncols = zip(cols.index, map(lambda x: l[x.name] + ' encode zstd', cols.values))\ncols = \", \".join(map(lambda x: ' '.join(x), cols))"
  },
  {
    "objectID": "posts/airflow/index.html",
    "href": "posts/airflow/index.html",
    "title": "airflow",
    "section": "",
    "text": "this dag has an expanding training window with a maximum amount.\nwe found that three years worth of data was perferable, and anything further would degrade performance.\nalso, the backtest needed to start in 2011, which was only 1 year after the training data began.\nso, for the first two years the training data window would expand to a maximum of three years, then retain only the most recent three years.\n\nwhat makes this difficult is airflow does not allow python in the dag.\nto get around this, I wrote the functions outside the dag & used the built in airflow utilities for date manipulation & function execution.\nPythonOperator grabbed the functions and macros.ds_add() manipulated the training & prediction windows\nthese windows were set here in the file, but I probably shoud’ve used a CLI like click\nfrom datetime import datetime, timedelta\nimport pendulum\nfrom airflow import DAG\nfrom airflow.models import Variable\nfrom airflow.operators.bash_operator import BashOperator\nfrom airflow.operators.python import PythonOperator\nfrom airflow.providers.docker.operators.docker import DockerOperator\nfrom docker.types import Mount\n\ndefault_arguments = {\n    \"owner\": \"airflow\",\n    \"depends_on_past\": True,\n    \"retries\": 0,\n}\n\ndef check_start_date(**kwargs):\n    date_given = kwargs['date']\n    if date_given &gt; '2010-01-01':\n        return date_given\n    else:\n        return '2010-01-01'\n\ndef check_end_date(**kwargs):\n    date_given = kwargs['date']\n    if date_given &lt; '2020-12-31':\n        return date_given\n    else:\n        return '2020-12-31'\n\nwith DAG(\n    dag_id=\"backfiill data_pull\",\n    description=\"Backfill DAG for data pulls\",\n    schedule_interval=timedelta(days=100),\n    start_date = pendulum.datetime(2011, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    default_args=default_arguments,\n) as dag:\n\n\n    format_start_date = PythonOperator(\n        task_id='format_start_date',\n        python_callable=check_start_date,\n        op_kwargs={\"date\":\"{{ macros.ds_add(ds, -1096) }}\"},\n    )\n    format_end_date = PythonOperator(\n        task_id='format_end_date',\n        python_callable=check_end_date,\n        op_kwargs={\"date\":\"{{ macros.ds_add(ds, 99) }}\"},\n    )\n\n    training_date_start =  \"{{ ti.xcom_pull(task_ids='format_start_date') }}\"\n    training_date_end = \"{{ macros.ds_add(ds, -1) }}\"\n\n    prediction_period_start = \"{{ ds }}\"\n    prediction_period_end =  \"{{ ti.xcom_pull(task_ids='format_end_date') }}\"\n\n\n    docker_url = Variable.get(\"DOCKER_URL\", deserialize_json=True)\n    aws_user = Variable.get(\"AWS_USERNAME\", deserialize_json=True)\n\n    training_data_pull = DockerOperator(\n        task_id=\"training_data_pull\",\n        image=\"image_name:latest\",\n        command=f\"python scripts/data_pull.py \\\n            --aws_user {aws_user} \\\n            --start_date {training_date_start} \\\n            --end_date {training_date_end}\",\n        network_mode='host',\n        docker_url=docker_url,\n        auto_remove=True,\n        mounts=[\n            Mount(target='/home/myuser/.aws', source='/home/airflow/.aws', type='bind'),\n            Mount(target='/home/myuser/code/scripts', source='/home/airflow/projects', type='bind')\n            ],\n        dag=dag\n    )\n\n    prediction_data_pull = DockerOperator(\n        task_id=\"prediction_data_pull\",\n        image=\"image_name:latest\",\n        command=f\"python scripts/data_pull.py \\\n            --aws_user {aws_user} \\\n            --start_date {prediction_period_start} \\\n            --end_date {prediction_period_end}\",\n        network_mode='host',\n        docker_url=docker_url,\n        auto_remove=True,\n        mounts=[\n            Mount(target='/home/myuser/.aws', source='/home/airflow/.aws', type='bind'),\n            Mount(target='/home/myuser/code/scripts', source='/home/airflow/projects', type='bind')\n            ],\n        dag=dag\n    )\n\n    format_start_date &gt;&gt; format_end_date &gt;&gt; training_data_pull &gt;&gt; prediction_data_pull"
  },
  {
    "objectID": "posts/docker/index.html",
    "href": "posts/docker/index.html",
    "title": "docker",
    "section": "",
    "text": "Two stage Dockerfile. Runner image is slim with only virtual environment.\nFROM ubuntu:20.04 AS builder-image\n\n# avoid stuck build due to user prompt\nARG DEBIAN_FRONTEND=noninteractive\n\nRUN apt-get update && \\\n    apt-get install --no-install-recommends -y python3.9 python3.9-dev python3.9-venv python3-pip python3-wheel build-essential && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/*\n\n# create and activate virtual environment\n# using final folder name to avoid path issues with packages\nRUN python3.9 -m venv /home/myuser/venv\nENV PATH=\"/home/myuser/venv/bin:$PATH\"\n\n# install requirements\nCOPY app/requirements.txt .\nRUN pip3 install --no-cache-dir wheel\nRUN pip3 install --no-cache-dir -r requirements.txt\n\nFROM ubuntu:20.04 AS runner-image\nRUN apt-get update && \\\n    apt-get install --no-install-recommends -y python3.9 python3-venv && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/*\n\nRUN useradd --create-home myuser\nCOPY --from=builder-image /home/myuser/venv /home/myuser/venv\n\nUSER myuser\nRUN mkdir /home/myuser/code\nWORKDIR /home/myuser/code\nCOPY app .\n\n# make sure all messages always reach console\nENV PYTHONUNBUFFERED=1\n\n# activate virtual environment\nENV VIRTUAL_ENV=/home/myuser/venv\nENV PATH=\"/home/myuser/venv/bin:$PATH\"\nI’ve been told installing python manually is not worth the effort & nudged to use the official docker python images.\nThis is good advice, because I have struggled with C package installs (specifically for LGBM).\n\nCreate a container & attach a volume to the image. This command opens the container in interactive mode, mounts the /app directory as a volumne, and links the port 8080.\nThis is useful because changes to application, or whatever you are working on, are reflected inside of the docker container.\nI have been using this with streamlit, but I believe it should work with jupyter. Linking to jupyter through a docker container is a pain, so maybe not. I’ll have to check.\ndocker run -it --rm -v $(pwd)/app:/home/myuser/code -p 8080:8080 img_name\n\nIf your environment requires variables you can pass them through with --env-file\ndocker run --env-file .env-local \nWith the format:\nDS_BUCKET=XXXX\nAWS_ACCESS_KEY_ID_DEV=XXXX\nAWS_SECRET_ACCESS_KEY_DEV=XXXX"
  },
  {
    "objectID": "posts/pipeline/index.html",
    "href": "posts/pipeline/index.html",
    "title": "pipeline",
    "section": "",
    "text": "import inspect\nimport numpy as np\nimport pandas as pd\nfrom scipy.special import expit\nfrom utils import map_idx, RidgeRegTransformer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import FeatureUnion, Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\n\nCreate data\n\n# random number generator\nrng = np.random.default_rng(1995)\n\ndata = pd.DataFrame(\n    {\n        'm1_feat1': rng.normal(20, 5, 1000),\n        'm1_feat2': rng.normal(25, 15, 1000),\n        'm2_feat1': rng.normal(10, 2, 1000),\n        'm2_feat2': rng.normal(30, 10, 1000),\n        'm2_feat3': rng.normal(15, 10, 1000),        \n})\n\ndata['m1_target'] = data['m1_feat1']*10.0 + data['m1_feat1']*5.0 + rng.normal(0, 5, 1000)\ndata['m2_target'] = data['m2_feat1']*10.0 + data['m2_feat2']*5.0 + data['m2_feat3']*1.2 + rng.normal(0, 5, 1000)\n\ndata['target'] = expit(data['m1_target']*-1.10 + data['m2_target']*1.20 + rng.normal(0, 100, 1000)).round()\n\n\nPrep setup\nCreate lists which refer to the required columns. I like using the indexes rather than the names, so I convert them all to indicies. But I believe RidgeRegTransformer can take either. Check out the code here.\nThe target index needs to be the last item in the list.\n\nmodel1_features = ['m1_feat1','m1_feat2']\nmodel2_features = ['m2_feat1','m2_feat2','m2_feat3']\n\nmodel1_target = ['m1_target']\nmodel2_target = ['m2_target']\n\nmodel1_idxs = map_idx(data, model1_features) + map_idx(data, model1_target)\nmodel2_idxs = map_idx(data, model2_features) + map_idx(data, model2_target)\n\nmodel1_target_idx = len(model1_idxs) - 1\nmodel2_target_idx = len(model2_idxs) - 1\n\nmodel1_params = {\"scaler\": StandardScaler(), \"alpha\": 10}\nmodel2_params = {\"scaler\": StandardScaler(), \"alpha\": 10}\nmeta_params = {\"C\": 0.20}\n\nI am passing the StandardScaler to the regressions models via a dictionary. When the function is called the scaler is attached to the object.\nIt doesn’t feel right. I think instead the scaler should be passed in the pipeline somewhere, but then I’d have to create a sub-sub pipeline? Seems like too much\n\nTwo models with different targets and inputs\n\nmulti_model_transformer = ColumnTransformer(\n    [\n        (\n            \"model1\",\n            RidgeRegTransformer(estimator_target=model1_target_idx, **model1_params),\n            model1_idxs,\n        ),\n        (\n            \"model2\",\n            RidgeRegTransformer(estimator_target=model2_target_idx, **model2_params),\n            model2_idxs,\n        )\n    ],\n    remainder=\"drop\"\n)\n\n\nAdd meta classifier, which uses the underlying model’s predictions as input\nCan also add a passthrough to the ColumnTransformer, which will passthrough other columns from the original dataset\n\npipe = Pipeline(\n    [\n        (\"feat_transformer\", multi_model_transformer),\n        (\"meta_classifier\", LogisticRegression(**meta_params))\n    ]\n)\n\nFit the underylying ridge models & then the logistic regression\n\npipe.fit(data.values, data['target'])\n\nPipeline(steps=[('feat_transformer',\n                 ColumnTransformer(transformers=[('model1',\n                                                  RidgeRegTransformer(alpha=10,\n                                                                      estimator_target=2,\n                                                                      scaler=StandardScaler()),\n                                                  [0, 1, 5]),\n                                                 ('model2',\n                                                  RidgeRegTransformer(alpha=10,\n                                                                      estimator_target=3,\n                                                                      scaler=StandardScaler()),\n                                                  [2, 3, 4, 6])])),\n                ('meta_classifier', LogisticRegression(C=0.2))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('feat_transformer',\n                 ColumnTransformer(transformers=[('model1',\n                                                  RidgeRegTransformer(alpha=10,\n                                                                      estimator_target=2,\n                                                                      scaler=StandardScaler()),\n                                                  [0, 1, 5]),\n                                                 ('model2',\n                                                  RidgeRegTransformer(alpha=10,\n                                                                      estimator_target=3,\n                                                                      scaler=StandardScaler()),\n                                                  [2, 3, 4, 6])])),\n                ('meta_classifier', LogisticRegression(C=0.2))])feat_transformer: ColumnTransformerColumnTransformer(transformers=[('model1',\n                                 RidgeRegTransformer(alpha=10,\n                                                     estimator_target=2,\n                                                     scaler=StandardScaler()),\n                                 [0, 1, 5]),\n                                ('model2',\n                                 RidgeRegTransformer(alpha=10,\n                                                     estimator_target=3,\n                                                     scaler=StandardScaler()),\n                                 [2, 3, 4, 6])])model1[0, 1, 5]scaler: StandardScalerStandardScaler()StandardScalerStandardScaler()model2[2, 3, 4, 6]scaler: StandardScalerStandardScaler()StandardScalerStandardScaler()LogisticRegressionLogisticRegression(C=0.2)\n\n\nProduce probabilities for target\n\npipe.predict_proba(data.values)[:5]\n\narray([[0.4386381 , 0.5613619 ],\n       [0.05467618, 0.94532382],\n       [0.75733447, 0.24266553],\n       [0.23029838, 0.76970162],\n       [0.49828572, 0.50171428]])\n\n\n\nThe base pipelines can also be estimators in a meta Pipeline VotingClassifier. Something like:\nmeta_pipe = Pipeline(\n    [\n        [\n            \"meta_pipe\",\n            VotingClassifier(\n                estimators=[\n                    (\"pipe1\", multi_model_transformer1),\n                    (\"pipe2\", multi_model_transformer2),\n                    (\"pipe3\", multi_model_transformer3)\n                ],\n                voting=\"soft\",\n            ),\n        ]\n    ]\n)\n\nmeta_pipe.fit(data.values, data[\"target\"])"
  },
  {
    "objectID": "posts/llm/index.html",
    "href": "posts/llm/index.html",
    "title": "LLM",
    "section": "",
    "text": "WIP\ncool package instructor\nmanual indexing was beaten out of me at my first job, so when I saw this online I had to check it out.\nlooks like a cool package too.\n#| eval: false\nfrom dotenv import load_dotenv\nload_dotenv('../.env')\n#| eval: false\nfrom io import StringIO\nfrom typing import Annotated, Any, Iterable\nfrom openai import OpenAI\nfrom pydantic import (\n    BaseModel,\n    BeforeValidator,\n    PlainSerializer,\n    InstanceOf,\n    WithJsonSchema,\n)\nimport pandas as pd\nimport instructor\n\n\nclient = instructor.patch(OpenAI(), mode=instructor.function_calls.Mode.MD_JSON)\n\n\ndef to_markdown(df: pd.DataFrame) -&gt; str:\n    return df.to_markdown()\n\n\ndef md_to_df(data: Any) -&gt; Any:\n    if isinstance(data, str):\n        return (\n            pd.read_csv(\n                StringIO(data),  # Get rid of whitespaces\n                sep=\"|\",\n                index_col=1,\n            )\n            .dropna(axis=1, how=\"all\")\n            .iloc[1:]\n            .map(lambda x: x.strip())\n        )\n    return data\n\n\nMarkdownDataFrame = Annotated[\n    InstanceOf[pd.DataFrame],\n    BeforeValidator(md_to_df),\n    PlainSerializer(to_markdown),\n    WithJsonSchema(\n        {\n            \"type\": \"string\",\n            \"description\": \"\"\"\n                The markdown representation of the table, \n                each one should be tidy, do not try to join tables\n                that should be seperate\"\"\",\n        }\n    ),\n]\n\n\nclass Table(BaseModel):\n    caption: str\n    dataframe: MarkdownDataFrame\n\n\ndef extract_table(url: str) -&gt; Iterable[Table]:\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Iterable[Table],\n        max_tokens=1800,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": \"\"\"Extract the table from the image, and describe it. \n                        Each table should be tidy, do not try to join tables that \n                        should be seperately described.\"\"\",\n                    },\n                    {\n                        \"type\": \"image_url\",\n                        \"image_url\": {\"url\": url},\n                    },\n                ],\n            }\n        ],\n    )\n#| eval: false\nurl = \"https://a.storyblok.com/f/47007/2400x2000/bf383abc3c/231031_uk-ireland-in-three-charts_table_v01_b.png\"\ntables = extract_table(url)\nfor tbl in tables:\n    print(tbl.caption, end=\"\\n\")\n    print(tbl.dataframe)"
  },
  {
    "objectID": "posts/NGBoost/index.html",
    "href": "posts/NGBoost/index.html",
    "title": "Ngboost",
    "section": "",
    "text": "A few years ago the Standford ML Group released NGBoost.\nThey describe it as:\n\nNGBoost generalizes gradient boosting to probabilistic regression by treating the parameters of the conditional distribution as targets for a multiparameter boosting algorithm.\n\n…\n\nOur key innovation is in employing the natural gradient to perform gradient boosting by casting it as a problem of determining the parameters of a probability distribution.\n\nWith this learned distribution, you can get the mean & stdev at a given value. Also, it allows you to model the joint distribution of two variables.\nHere, I am using the veterans dataset. ngb.pred_dist returns a scipy.stats object, so it has the method .cdf()\n\nimport pandas as pd\nimport numpy as np\nfrom ngboost import NGBSurvival\nfrom ngboost.distns import LogNormal\nimport plotly.express as px\n\nd = pd.read_csv('veteran.csv')\n\nX = d[['trt']].values\nT = d[['time']].values\nE = d[['status']].values\n\nngb = NGBSurvival(\n    Dist=LogNormal,\n    n_estimators=100).fit(X, T, E)\n\npreds = ngb.predict(X)\ndist = ngb.pred_dist([[1],[2]]) # treatment 1 & 2\n\nest_times = (\n    pd.DataFrame(\n        [np.concatenate([[t], dist.cdf(t)]) for t in range(0,250,2)],\n        columns=['time','trt1','trt2'])\n)\n\nfig = px.line(est_times, x='time', y=['trt1','trt2'])\nfig.show()\n\n[iter 0] loss=5.4733 val_loss=0.0000 scale=2.0000 norm=2.5423"
  },
  {
    "objectID": "posts/indy/index.html",
    "href": "posts/indy/index.html",
    "title": "Indianapolis: Crime Downtown",
    "section": "",
    "text": "Indianapolis is smack dab in the middle of Indiana, which is a conservative state. Therefore, conservative talk radio is abundant. One of my guilty pleasures is conservative talk radio. I can’t count the number of times my father had Rush Limbaugh on in the car. The radioman was an additional, parasocial crazy uncle. I have always had some form of conservative media in my life. Hearing old men gasp at the latest liberal cultural transgression makes me feel nostologic & at home.\nIf you were to take these guys1 seriously, you’d think Indianapolis was a war zone. It is true that Indianapolis has a lot of violence, so their warnings are not totally without merit. But when I hear them talk about the violence in Indianapolis, I think of downtown.\nI’ve lived in downtown Indianapolis for three years. I have never felt in danger. So, what gives? Maybe it’s that I am a large dude (I’ve lost some weight since my playing days I swear). My wife does feel uncomfortable “near the circle”. I’ve heard her mother, an Irvington resident, say similar things.\nIs downtown actually dangerous?\nI am going to only consider Violent Crime, which in this dataset falls into one of these Categories: Homicide, Robbery, Assault, or Sexual Offense.\nIMPD releases crime data with coordinates. This is the 2021 UCR data. Let’s check it out.\n\nMarion County\nHere is a table of the violent crime for all of Marion County.\n\nimpd_data |&gt;\n  count(CRIME) |&gt; \n  arrange(desc(n)) |&gt;\n  rename(Occurances=n) |&gt;\n  kable()\n\n\n\n\nCRIME\nOccurances\n\n\n\n\nAGGRAVATED ASSAULT-GUN\n4112\n\n\nAGGRAVATED ASSAULT-OTHER WEA\n1208\n\n\nAGGRAVATED ASSAULT-HANDS,FIS\n658\n\n\nAGGRAVATED ASSAULT-KNIFE\n651\n\n\nRAPE\n524\n\n\nROBBERY-ARMED-RESIDENCE\n317\n\n\nROBBERY-ARMED-HIWAY\n302\n\n\nCRIMINAL HOMICIDE\n245\n\n\nROBBERY-ARMED-COMMERCIAL HOU\n221\n\n\nATTEMPT ARMED ROBBERY\n176\n\n\nROBBERY-ARMED-MISCELLANEOUS\n167\n\n\nROBBERY-STRONG ARM-HIWAY\n130\n\n\nROBBERY-ARMED-OIL STATION\n110\n\n\nROBBERY-STRONG ARM-RESIDENCE\n91\n\n\nROBBERY-STRONG ARM-MISCELLAN\n63\n\n\nATTEMPT STRONG ARMED ROBBERY\n53\n\n\nROBBERY-ARMED-CHAIN STORE\n49\n\n\nROBBERY-STRONG ARM-COMMERCIA\n49\n\n\nRAPE-ATTEMPT\n39\n\n\nROBBERY-STRONG ARM-OIL STATI\n30\n\n\nROBBERY-ARMED-BANK\n15\n\n\nROBBERY-STRONG ARM-CHAIN STO\n9\n\n\nROBBERY-STRONG ARM-BANK\n5\n\n\nAGGRAVATED ASSAULT-OTHER WE\n1\n\n\n\n\n\n\n\nHere is a cluster map of the individual crimes from Marion County. You can zoom in to find more info.\n\n\n\n\n\n\n\n\nHow to define downtown?\nWhen Hoosiers say downtown, I’d be willing to bet they mean somewhere close to the circle. I doubt most would consider Holy Cross, a neighbor just east of our boundary, downtown.\nI am going to define downtown using US Census Tracts, which provide a nice boundary and population data. So, I will consider crimes that happen within this boundary as downtown crimes.\nThere were a total of 430 violent crimes downtown last year.\n\n\n\n\nDowntown Indianapolis: Census Tracts\n\n\n\n\nWhat’s the population of downtown?\nAccording to the Census, the population of downtown is ~20,000 people. For our purposes, is this supposed to represent the number of people downtown all year? I have roughly a years worth of data, from January to January (2023 to 2024). Were there 20 thousand people in downtown Indianapolis throughout the year? That can’t be right. On a Saturday during the summer I bet nearly 20,000 extra people are downtown.\nAccording to Placer.ai, a website which estimates monthly visits to various locations, there are about ~300,000 monthly visits to zip code 46204, which contains much of downtown including the circle. Does that mean there were 300K x 12 (months) people downtown over the year?\nGainsbridge Fieldhouse hosts 2 million guests per year. How should we count this influx of people?\nFinally, the VisitIndy people say there are 30 million annual visitors to Indianapolis.\nThis is genuinely confusing, and I am not sure how to resolve it. If anyone has a good idea please let me know.\nThe question I want to answer is:\n\nHow likely are you to be near or victim of a crime when visiting downtown?\n\nTo answer this, I need the number of crimes per day divided by the number of people downtown per day.\nIf I take VisitIndy’s estimate at face value, that would mean on average there are 30,000,000 / 365 = ~82,000 people downtown. This seems way to high. The standard deviation, due to sports matches, holidays, and various events, is probably large. I’d be willing to bet the average is closer to 40,000 to 50,000 people who come to downtown each day. So, I’ll split that range and call it 45,000. This will be my number of people in downtown Indianapolis each day.\n\n\nHow many crimes are there per day?\nThere are a total of 430 violent crimes downtown in the year. That is 1.17 violent crimes per day.\n\n\nHow many crimes are there per meter2?\nThe total area downtown is about 10 million meters2. A single square meter is about 10 square feet, like a small room. There are 1.17 crimes downtown per day divided by 10 million meters2. That is equal to 0.0000001 crimes per day per meter2.\nOr, put another way, for any given 10x10 foot spot downtown you have a 1 in 10 million chance of being in the same spot as a violent crime.\n\ndowntown_area &lt;- sum(downtown$area) \n# there are 0.000000119 crimes per day per meter downtown\n# I like those odds\n(crime_per_day / downtown_area)\n\n1.194498e-07 [1/m^2]\n\n\n\n\nWhat is the crime per 100 people?\nBack to population, there are ~0.002 violent crimes per day per 100 people downtown.\n\n# for every 100 people downtown, there are 0.002 violent crimes\n(crime_per_day / downtown_pop)*100\n\n[1] 0.00261796\n\n\n\n\nIs there more crime in the Circle?\nMy conservative uncles, and my beloved mother-in-law, may have the right intuition when it comes to the circle. The crime in the circle is higher than the rest of downtown.\nInstead of 0.0000001 crimes per day per meter2, there are 0.0000006 crimes per day per meter2. The latter number is higher than the former. Is the difference significant? What do you think?\n\n\n\n\n\n\n\n\n\n\n\nFootnotes\n\n\nTony Kats, Robert Evans, & Tony Kinnett↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "Title\n\n\nCategories\n\n\nDate\n\n\n\n\n\n\nConsumer Sentiment\n\n\npost\n\n\nAug 1, 2025\n\n\n\n\nNgboost\n\n\ncode, survival\n\n\nJan 18, 2024\n\n\n\n\nIndianapolis: Crime Downtown\n\n\npost\n\n\nJan 13, 2024\n\n\n\n\npipeline\n\n\ncode, sklearn, Pipeline\n\n\nDec 27, 2023\n\n\n\n\npandas\n\n\ncode, dates, timeseries\n\n\nDec 20, 2023\n\n\n\n\nLLM\n\n\ncode, LLM\n\n\nDec 16, 2023\n\n\n\n\ndocker\n\n\ncode, analysis\n\n\nDec 2, 2023\n\n\n\n\nairflow\n\n\ncode\n\n\nDec 2, 2023\n\n\n\n\n\nNo matching items"
  }
]