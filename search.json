[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Vincenzo Palazeti",
    "section": "",
    "text": "My name is Vincenzo Palazeti, but everyone calls me Vinnie.\nI am a Data Scientist at Vevo. My main focus thus far has been forecasting various quantities. Inventory, Views, Watch Time, Revenue, etc.\nPrior to Vevo, I worked for several startups in the Sports & Horse wagering industries. Some of the topics I’ve spent time on are yield optimization, ensembling methods, ranking algorthims, timeseries, experimental methods, & data engineering."
  },
  {
    "objectID": "about.html#hello",
    "href": "about.html#hello",
    "title": "Vincenzo Palazeti",
    "section": "",
    "text": "My name is Vincenzo Palazeti, but everyone calls me Vinnie.\nI am a Data Scientist at Vevo. My main focus thus far has been forecasting various quantities. Inventory, Views, Watch Time, Revenue, etc.\nPrior to Vevo, I worked for several startups in the Sports & Horse wagering industries. Some of the topics I’ve spent time on are yield optimization, ensembling methods, ranking algorthims, timeseries, experimental methods, & data engineering."
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Vincenzo Palazeti",
    "section": "Experience",
    "text": "Experience\n\n\n Data Scientist, 2023-Present\n\n\nVevo\n\n\n Data Scientist / Engineer, 2020-2023\n\n\nIndy Stats\n\n\n Statistician, 2019-2020\n\n\nCenter for Criminal Justice Research\n\n\n Finance Team, 2017-2019\n\n\nMagna Powertrain"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Vincenzo Palazeti",
    "section": "Education",
    "text": "Education\n\n\n MS in Applied Statistics, 2020\n\n\nUniversity of Loyola Chicago\n\n\n BS in Professional Selling, 2017\n\n\nBall State University"
  },
  {
    "objectID": "posts/pandas/index.html",
    "href": "posts/pandas/index.html",
    "title": "pandas",
    "section": "",
    "text": "Grab all of the month names\nmonths = pd.date_range('2020-01-01','2020-12-31',freq='MS').map(lambda x: x.month_name())\npandas types to redshift schema\ncols = d.dtypes\nl = {'object':'varchar(255)', 'int64':'bigint','float64':'double precision','datetime64[ns]':'date'}\ncols = zip(cols.index, map(lambda x: l[x.name] + ' encode zstd', cols.values))\ncols = \", \".join(map(lambda x: ' '.join(x), cols))"
  },
  {
    "objectID": "posts/consumer_sent/index.html",
    "href": "posts/consumer_sent/index.html",
    "title": "Consumer Sentiment",
    "section": "",
    "text": "There has been an ongoing twitter conversation concerning the Michigan Consumer Sentiment Survey. The gap between the Actual & “Expected” survey index has grown too large, and people are searching for an explanation. The Expected index is determined by using economic indicators in a linear regression model.\nFrom what I can tell, there are two main args: Vibe-cession & Economy-bad\nThe main vibe-cession theorist Will Stancil has suggested that this divergence is due to negative media bias & leftist doomerism.\nOpposing view points have come from Guy Berger, Matt Bruenig, and Gabrial Zucman, who have suggested the decrease in Real Income (Overall, Disposable, Excluding Transfers, etc) has negativly1 impacted consumer sentiment.\nThe economist Matt Darling has pushed back on the opposing position. In the linked tweet, Darling asks Bruenig if he has looked at the Actual - Expected Index using his proposed variables. Matt (Bruenig) did not respond.\nI decided to take a look. I use the suggested variables from Darling, Berger, & Zucman to model the Michigan Survey Consumer Index. I have not seen an index or measure from Will, so I am not sure how to test his hypothesis.\nFirst I take a look at the monthly data, then I group by year."
  },
  {
    "objectID": "posts/consumer_sent/index.html#expected-vs-actual",
    "href": "posts/consumer_sent/index.html#expected-vs-actual",
    "title": "Consumer Sentiment",
    "section": "Expected vs Actual",
    "text": "Expected vs Actual\nThis is a plot of the Actual & Expected Consumer Index.\n\n\n                                                \n\n\n\nThis is the money shot. The vibe-cession discourse boils down to figuring out what is causing this divergence between consumer sentiment & economic indicators.\n\n\n\n                                                \n\n\n\nIncluding the Real Income reduces the residual by about 15%, but it does not close the gap entirely. So, using this framework, the opposing view does not totally explain the divergence.\nIf we look at the Residuals (Actual - Expected) over time, we are lead to an interesting result.\n\n\n\n                                                \n\n\n\nA large gap in Consumer Sentiment has happened in the recent past. The 2008 financial crisis caused a similar divergence in actual vs expected.\n\n\n\n                                                \n\n\n\nThis gap was in the opposite direction, i.e. Consumer Sentiment was lower that the model would estimate."
  },
  {
    "objectID": "posts/consumer_sent/index.html#results",
    "href": "posts/consumer_sent/index.html#results",
    "title": "Consumer Sentiment",
    "section": "Results",
    "text": "Results\nWith this setup, it looks like economic shocks can result in large residuals.\nThese time periods are irregular economic circumstances, so it’s intuitive, to me at least, that the normal economic indicators might not explain sentiment very well."
  },
  {
    "objectID": "posts/consumer_sent/index.html#unemployment-vs-rdi",
    "href": "posts/consumer_sent/index.html#unemployment-vs-rdi",
    "title": "Consumer Sentiment",
    "section": "Unemployment vs RDI",
    "text": "Unemployment vs RDI\nThe residual gap is caused by including Unemployment in the model. This is clear if we fit a model with only Unemployment Rate.\n\n\n                                                \n\n\n\nOn the opposite end, Real Disposable Income is the main downward driver. In terms of information about consumer sentiment, the variable RDI_pct_change_24 has the slight edge over Unemployment Rate. The former has a higher R^2 & lower AIC and BIC."
  },
  {
    "objectID": "posts/consumer_sent/index.html#results-1",
    "href": "posts/consumer_sent/index.html#results-1",
    "title": "Consumer Sentiment",
    "section": "Results",
    "text": "Results\nI did not rehash the idea here, but I still think the economic shock theory is a good one.\nOverall, low Unemployment has a positive impact on sentiment, while diminishing RDI has a negative one.\nI think it’s plausible that such a drastic decrease in Real Disposable Income (the largest recorded in our data) could be playing a large role than we are unable to measure appropriately.\nHonestly, this graph is wild."
  },
  {
    "objectID": "posts/consumer_sent/index.html#footnotes",
    "href": "posts/consumer_sent/index.html#footnotes",
    "title": "Consumer Sentiment",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEconomy-bad↩︎\nAIC,BIC,& R^2↩︎"
  },
  {
    "objectID": "posts/quarto_envs/index.html",
    "href": "posts/quarto_envs/index.html",
    "title": "Multiple Virtual Environments",
    "section": "",
    "text": "Quarto does not allow multiple virtual environments to be used in a single quarto render call.\nTo work around this, I wrote a script that renders each index.qmd in my posts directory. It sets the QUARTO_PYTHON variable for each render.\nI use pyenv. The paths to the python executable is in the hidden .pyenv directory. Pyenv caches the package downloads, which saves a lot of space. Naming the environment the same as the post allows me to use the shared name as the dictonary key.\nFinally, render the whole project. I use freeze: true in the posts/_metadata.yml, so this last render does not affect what was just accomplished.\n(also, my initials are mvp. I swear I am not that conceded)\nimport os\nimport subprocess\n\nenvs = {\n    'base':\"/Users/mvp/.pyenv/versions/quarto_base/bin/python\",\n    'NGBoost':\"/Users/mvp/.pyenv/versions/NGBoost/bin/python\",\n    'llm':\"/Users/mvp/.pyenv/versions/llm/bin/python\",\n}\n\ndir = os.path.join(os.getcwd(),'posts') \npaths = [i for i in os.listdir(dir) if '.' not in i]\n\nfor path in paths:\n    if path in envs.keys():\n        python_v = envs[path]\n    else:\n        python_v = envs['base']\n    print(f'rendering...')\n    process = f'QUARTO_PYTHON={python_v} quarto render posts/{path}/index.qmd'\n    print(f'cmd: {process}')\n    result = subprocess.run(process, shell=True)\n\nsubprocess.run(\"quarto render\", shell=True)\nI tried to use the pre-render argument in _quarto.yml, but I would get this weird error where the render would stall.\nproject:\n  type: website\n  pre-render: multienv.py\n\nwebsite:\n  title: Posts\n  navbar:\n  ...\nIn theory this should work with just one quarto render (if I removed the last subprocess.run). I couldn’t get it to run, so I just use python multienv.py"
  },
  {
    "objectID": "posts/airflow/index.html",
    "href": "posts/airflow/index.html",
    "title": "airflow",
    "section": "",
    "text": "this dag has an expanding training window with a maximum amount.\nwe found that three years worth of data was perferable, and anything further would degrade performance.\nalso, the backtest needed to start in 2011, which was only 1 year after the training data began.\nso, for the first two years the training data window would expand to a maximum of three years, then retain only the most recent three years.\n\nwhat makes this difficult is airflow does not allow python in the dag.\nto get around this, I wrote the functions outside the dag & used the built in airflow utilities for date manipulation & function execution.\nPythonOperator grabbed the functions and macros.ds_add() manipulated the training & prediction windows\nthese windows were set here in the file, but I probably shoud’ve used a CLI like click\nfrom datetime import datetime, timedelta\nimport pendulum\nfrom airflow import DAG\nfrom airflow.models import Variable\nfrom airflow.operators.bash_operator import BashOperator\nfrom airflow.operators.python import PythonOperator\nfrom airflow.providers.docker.operators.docker import DockerOperator\nfrom docker.types import Mount\n\ndefault_arguments = {\n    \"owner\": \"airflow\",\n    \"depends_on_past\": True,\n    \"retries\": 0,\n}\n\ndef check_start_date(**kwargs):\n    date_given = kwargs['date']\n    if date_given &gt; '2010-01-01':\n        return date_given\n    else:\n        return '2010-01-01'\n\ndef check_end_date(**kwargs):\n    date_given = kwargs['date']\n    if date_given &lt; '2020-12-31':\n        return date_given\n    else:\n        return '2020-12-31'\n\nwith DAG(\n    dag_id=\"backfiill data_pull\",\n    description=\"Backfill DAG for data pulls\",\n    schedule_interval=timedelta(days=100),\n    start_date = pendulum.datetime(2011, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    default_args=default_arguments,\n) as dag:\n\n\n    format_start_date = PythonOperator(\n        task_id='format_start_date',\n        python_callable=check_start_date,\n        op_kwargs={\"date\":\"{{ macros.ds_add(ds, -1096) }}\"},\n    )\n    format_end_date = PythonOperator(\n        task_id='format_end_date',\n        python_callable=check_end_date,\n        op_kwargs={\"date\":\"{{ macros.ds_add(ds, 99) }}\"},\n    )\n\n    training_date_start =  \"{{ ti.xcom_pull(task_ids='format_start_date') }}\"\n    training_date_end = \"{{ macros.ds_add(ds, -1) }}\"\n\n    prediction_period_start = \"{{ ds }}\"\n    prediction_period_end =  \"{{ ti.xcom_pull(task_ids='format_end_date') }}\"\n\n\n    docker_url = Variable.get(\"DOCKER_URL\", deserialize_json=True)\n    aws_user = Variable.get(\"AWS_USERNAME\", deserialize_json=True)\n\n    training_data_pull = DockerOperator(\n        task_id=\"training_data_pull\",\n        image=\"image_name:latest\",\n        command=f\"python scripts/data_pull.py \\\n            --aws_user {aws_user} \\\n            --start_date {training_date_start} \\\n            --end_date {training_date_end}\",\n        network_mode='host',\n        docker_url=docker_url,\n        auto_remove=True,\n        mounts=[\n            Mount(target='/home/myuser/.aws', source='/home/airflow/.aws', type='bind'),\n            Mount(target='/home/myuser/code/scripts', source='/home/airflow/projects', type='bind')\n            ],\n        dag=dag\n    )\n\n    prediction_data_pull = DockerOperator(\n        task_id=\"prediction_data_pull\",\n        image=\"image_name:latest\",\n        command=f\"python scripts/data_pull.py \\\n            --aws_user {aws_user} \\\n            --start_date {prediction_period_start} \\\n            --end_date {prediction_period_end}\",\n        network_mode='host',\n        docker_url=docker_url,\n        auto_remove=True,\n        mounts=[\n            Mount(target='/home/myuser/.aws', source='/home/airflow/.aws', type='bind'),\n            Mount(target='/home/myuser/code/scripts', source='/home/airflow/projects', type='bind')\n            ],\n        dag=dag\n    )\n\n    format_start_date &gt;&gt; format_end_date &gt;&gt; training_data_pull &gt;&gt; prediction_data_pull"
  },
  {
    "objectID": "posts/llm/index.html",
    "href": "posts/llm/index.html",
    "title": "LLM",
    "section": "",
    "text": "WIP\ncool package instructor\nmanual indexing was beaten out of me at my first job, so when I saw this online I had to check it out.\nlooks like a cool package too.\n#| eval: false\nfrom dotenv import load_dotenv\nload_dotenv('../.env')\n#| eval: false\nfrom io import StringIO\nfrom typing import Annotated, Any, Iterable\nfrom openai import OpenAI\nfrom pydantic import (\n    BaseModel,\n    BeforeValidator,\n    PlainSerializer,\n    InstanceOf,\n    WithJsonSchema,\n)\nimport pandas as pd\nimport instructor\n\n\nclient = instructor.patch(OpenAI(), mode=instructor.function_calls.Mode.MD_JSON)\n\n\ndef to_markdown(df: pd.DataFrame) -&gt; str:\n    return df.to_markdown()\n\n\ndef md_to_df(data: Any) -&gt; Any:\n    if isinstance(data, str):\n        return (\n            pd.read_csv(\n                StringIO(data),  # Get rid of whitespaces\n                sep=\"|\",\n                index_col=1,\n            )\n            .dropna(axis=1, how=\"all\")\n            .iloc[1:]\n            .map(lambda x: x.strip())\n        )\n    return data\n\n\nMarkdownDataFrame = Annotated[\n    InstanceOf[pd.DataFrame],\n    BeforeValidator(md_to_df),\n    PlainSerializer(to_markdown),\n    WithJsonSchema(\n        {\n            \"type\": \"string\",\n            \"description\": \"\"\"\n                The markdown representation of the table, \n                each one should be tidy, do not try to join tables\n                that should be seperate\"\"\",\n        }\n    ),\n]\n\n\nclass Table(BaseModel):\n    caption: str\n    dataframe: MarkdownDataFrame\n\n\ndef extract_table(url: str) -&gt; Iterable[Table]:\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Iterable[Table],\n        max_tokens=1800,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": \"\"\"Extract the table from the image, and describe it. \n                        Each table should be tidy, do not try to join tables that \n                        should be seperately described.\"\"\",\n                    },\n                    {\n                        \"type\": \"image_url\",\n                        \"image_url\": {\"url\": url},\n                    },\n                ],\n            }\n        ],\n    )\n#| eval: false\nurl = \"https://a.storyblok.com/f/47007/2400x2000/bf383abc3c/231031_uk-ireland-in-three-charts_table_v01_b.png\"\ntables = extract_table(url)\nfor tbl in tables:\n    print(tbl.caption, end=\"\\n\")\n    print(tbl.dataframe)"
  },
  {
    "objectID": "posts/pipeline/index.html",
    "href": "posts/pipeline/index.html",
    "title": "pipeline",
    "section": "",
    "text": "import inspect\nimport numpy as np\nimport pandas as pd\nfrom scipy.special import expit\nfrom utils import map_idx, RidgeRegTransformer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import FeatureUnion, Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\n\nCreate data\n\n# random number generator\nrng = np.random.default_rng(1995)\n\ndata = pd.DataFrame(\n    {\n        'm1_feat1': rng.normal(20, 5, 1000),\n        'm1_feat2': rng.normal(25, 15, 1000),\n        'm2_feat1': rng.normal(10, 2, 1000),\n        'm2_feat2': rng.normal(30, 10, 1000),\n        'm2_feat3': rng.normal(15, 10, 1000),        \n})\n\ndata['m1_target'] = data['m1_feat1']*10.0 + data['m1_feat1']*5.0 + rng.normal(0, 5, 1000)\ndata['m2_target'] = data['m2_feat1']*10.0 + data['m2_feat2']*5.0 + data['m2_feat3']*1.2 + rng.normal(0, 5, 1000)\n\ndata['target'] = expit(data['m1_target']*-1.10 + data['m2_target']*1.20 + rng.normal(0, 100, 1000)).round()\n\n\nPrep setup\nCreate lists which refer to the required columns. I like using the indexes rather than the names, so I convert them all to indicies. But I believe RidgeRegTransformer can take either. Check out the code here.\nThe target index needs to be the last item in the list.\n\nmodel1_features = ['m1_feat1','m1_feat2']\nmodel2_features = ['m2_feat1','m2_feat2','m2_feat3']\n\nmodel1_target = ['m1_target']\nmodel2_target = ['m2_target']\n\nmodel1_idxs = map_idx(data, model1_features) + map_idx(data, model1_target)\nmodel2_idxs = map_idx(data, model2_features) + map_idx(data, model2_target)\n\nmodel1_target_idx = len(model1_idxs) - 1\nmodel2_target_idx = len(model2_idxs) - 1\n\nmodel1_params = {\"scaler\": StandardScaler(), \"alpha\": 10}\nmodel2_params = {\"scaler\": StandardScaler(), \"alpha\": 10}\nmeta_params = {\"C\": 0.20}\n\nI am passing the StandardScaler to the regressions models via a dictionary. When the function is called the scaler is attached to the object.\nIt doesn’t feel right. I think instead the scaler should be passed in the pipeline somewhere, but then I’d have to create a sub-sub pipeline? Seems like too much\n\nTwo models with different targets and inputs\n\nmulti_model_transformer = ColumnTransformer(\n    [\n        (\n            \"model1\",\n            RidgeRegTransformer(estimator_target=model1_target_idx, **model1_params),\n            model1_idxs,\n        ),\n        (\n            \"model2\",\n            RidgeRegTransformer(estimator_target=model2_target_idx, **model2_params),\n            model2_idxs,\n        )\n    ],\n    remainder=\"drop\"\n)\n\n\nAdd meta classifier, which uses the underlying model’s predictions as input\nCan also add a passthrough to the ColumnTransformer, which will passthrough other columns from the original dataset\n\npipe = Pipeline(\n    [\n        (\"feat_transformer\", multi_model_transformer),\n        (\"meta_classifier\", LogisticRegression(**meta_params))\n    ]\n)\n\nFit the underylying ridge models & then the logistic regression\n\npipe.fit(data.values, data['target'])\n\nPipeline(steps=[('feat_transformer',\n                 ColumnTransformer(transformers=[('model1',\n                                                  RidgeRegTransformer(alpha=10,\n                                                                      estimator_target=2,\n                                                                      scaler=StandardScaler()),\n                                                  [0, 1, 5]),\n                                                 ('model2',\n                                                  RidgeRegTransformer(alpha=10,\n                                                                      estimator_target=3,\n                                                                      scaler=StandardScaler()),\n                                                  [2, 3, 4, 6])])),\n                ('meta_classifier', LogisticRegression(C=0.2))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  Pipeline?Documentation for PipelineiFittedPipeline(steps=[('feat_transformer',\n                 ColumnTransformer(transformers=[('model1',\n                                                  RidgeRegTransformer(alpha=10,\n                                                                      estimator_target=2,\n                                                                      scaler=StandardScaler()),\n                                                  [0, 1, 5]),\n                                                 ('model2',\n                                                  RidgeRegTransformer(alpha=10,\n                                                                      estimator_target=3,\n                                                                      scaler=StandardScaler()),\n                                                  [2, 3, 4, 6])])),\n                ('meta_classifier', LogisticRegression(C=0.2))])  feat_transformer: ColumnTransformer?Documentation for feat_transformer: ColumnTransformerColumnTransformer(transformers=[('model1',\n                                 RidgeRegTransformer(alpha=10,\n                                                     estimator_target=2,\n                                                     scaler=StandardScaler()),\n                                 [0, 1, 5]),\n                                ('model2',\n                                 RidgeRegTransformer(alpha=10,\n                                                     estimator_target=3,\n                                                     scaler=StandardScaler()),\n                                 [2, 3, 4, 6])]) model1[0, 1, 5] scaler: StandardScalerStandardScaler()  StandardScaler?Documentation for StandardScalerStandardScaler() model2[2, 3, 4, 6] scaler: StandardScalerStandardScaler()  StandardScaler?Documentation for StandardScalerStandardScaler()  LogisticRegression?Documentation for LogisticRegressionLogisticRegression(C=0.2) \n\n\nProduce probabilities for target\n\npipe.predict_proba(data.values)[:5]\n\narray([[0.43927083, 0.56072917],\n       [0.05444773, 0.94555227],\n       [0.76011489, 0.23988511],\n       [0.23032154, 0.76967846],\n       [0.49754283, 0.50245717]])\n\n\n\nThe base pipelines can also be estimators in a meta Pipeline VotingClassifier. Something like:\nmeta_pipe = Pipeline(\n    [\n        [\n            \"meta_pipe\",\n            VotingClassifier(\n                estimators=[\n                    (\"pipe1\", multi_model_transformer1),\n                    (\"pipe2\", multi_model_transformer2),\n                    (\"pipe3\", multi_model_transformer3)\n                ],\n                voting=\"soft\",\n            ),\n        ]\n    ]\n)\n\nmeta_pipe.fit(data.values, data[\"target\"])"
  },
  {
    "objectID": "posts/docker/index.html",
    "href": "posts/docker/index.html",
    "title": "docker",
    "section": "",
    "text": "Two stage Dockerfile. Runner image is slim with only virtual environment.\nFROM ubuntu:20.04 AS builder-image\n\n# avoid stuck build due to user prompt\nARG DEBIAN_FRONTEND=noninteractive\n\nRUN apt-get update && \\\n    apt-get install --no-install-recommends -y python3.9 python3.9-dev python3.9-venv python3-pip python3-wheel build-essential && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/*\n\n# create and activate virtual environment\n# using final folder name to avoid path issues with packages\nRUN python3.9 -m venv /home/myuser/venv\nENV PATH=\"/home/myuser/venv/bin:$PATH\"\n\n# install requirements\nCOPY app/requirements.txt .\nRUN pip3 install --no-cache-dir wheel\nRUN pip3 install --no-cache-dir -r requirements.txt\n\nFROM ubuntu:20.04 AS runner-image\nRUN apt-get update && \\\n    apt-get install --no-install-recommends -y python3.9 python3-venv && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/*\n\nRUN useradd --create-home myuser\nCOPY --from=builder-image /home/myuser/venv /home/myuser/venv\n\nUSER myuser\nRUN mkdir /home/myuser/code\nWORKDIR /home/myuser/code\nCOPY app .\n\n# make sure all messages always reach console\nENV PYTHONUNBUFFERED=1\n\n# activate virtual environment\nENV VIRTUAL_ENV=/home/myuser/venv\nENV PATH=\"/home/myuser/venv/bin:$PATH\"\nI’ve been told installing python manually is not worth the effort & nudged to use the official docker python images.\nThis is good advice, because I have struggled with C package installs (specifically for LGBM).\n\nCreate a container & attach a volume to the image. This command opens the container in interactive mode, mounts the /app directory as a volumne, and links the port 8080.\nThis is useful because changes to application, or whatever you are working on, are reflected inside of the docker container.\nI have been using this with streamlit, but I believe it should work with jupyter. Linking to jupyter through a docker container is a pain, so maybe not. I’ll have to check.\ndocker run -it --rm -v $(pwd)/app:/home/myuser/code -p 8080:8080 img_name\n\nIf your environment requires variables you can pass them through with --env-file\ndocker run --env-file .env-local \nWith the format:\nDS_BUCKET=XXXX\nAWS_ACCESS_KEY_ID_DEV=XXXX\nAWS_SECRET_ACCESS_KEY_DEV=XXXX"
  },
  {
    "objectID": "posts/trees/index.html",
    "href": "posts/trees/index.html",
    "title": "Trees",
    "section": "",
    "text": "Trees purportedly have the ability to estimate effects (nonlinear, quadratic, etc.) not explicitly stated in the design matrix. I’ve regurgitated this assertion in an several interviews. I probably should see if it’s true.\nHere are the libraries I will use. Minus marginaleffects, which would have made this process a lot easier.\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport marginaleffects as me \nimport statsmodels.formula.api as smf\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\nimport warnings\nwarnings.filterwarnings('ignore')\nHere’s a function to simulate random normal data with various means & standard deviations. I love goofy list/dict comprehensions, so I had to thow one in.\nnp.random.seed(0)\nf = lambda mu, sig, n: mu + sig * np.random.normal(size=n)\n\ndef sim_data(\n    n_samples: int = 10_000, \n    n_features: int = 3, \n    means: list = [-5,0,5],\n    stdevs: list = [1,1,1]\n    ) -&gt; pd.DataFrame:\n\n    # having some fun with python folks\n    d = pd.DataFrame({\n        f'X{i+1}':f(mu=m,sig=s,n=n) \n        for i,(m,s,n) \n        in enumerate(zip(means, stdevs, [n_samples]*len(means)))\n    })\n    return d"
  },
  {
    "objectID": "posts/trees/index.html#linear",
    "href": "posts/trees/index.html#linear",
    "title": "Trees",
    "section": "Linear",
    "text": "Linear\nFirst I’ll start simple with a linear effect. I create an outcome variable from my simulated data & plot the raw data of the effect I’d like to measure.\n\nd = sim_data()\nfeatures = ['X1','X2','X3']\nd['Y'] = 10 + d['X1']*-2 + d['X2']*1 + d['X3']*2 + f(0, 1, d.shape[0])\npx.scatter(d, x='X1', y='Y', title='Simulated X & derived Y').show()\n\n                                                \n\n\nEach model seems to recover the effect fairly well. I am holding the other variables, X2 & X3, at there average level.\n\n# damn I really need marginaleffects\nmod = LinearRegression().fit(d[features], d['Y'])\ngb = GradientBoostingRegressor(n_estimators=200).fit(d[features], d['Y'])\nrf = RandomForestRegressor(n_estimators=200).fit(d[features], d['Y'])\n\nnewdata = d[features].assign(X2 = lambda df: df['X2'].mean(), X3 = lambda df: df['X3'].mean())\nl_preds = mod.predict(newdata); g_preds = gb.predict(newdata); rf_preds = rf.predict(newdata)\nnewdata['Linear Regression'] = l_preds; newdata['Gradient Boosted Tree'] = g_preds; newdata['Random Forest'] = rf_preds\n\nfig = px.scatter(\n    newdata,\n    x='X1', \n    y=['Linear Regression','Gradient Boosted Tree','Random Forest'],\n    title='Fitted Values @ X1'\n)\nfig.update_layout(yaxis_title=\"Fitted Value\")\nfig.show()"
  },
  {
    "objectID": "posts/trees/index.html#quadratic",
    "href": "posts/trees/index.html#quadratic",
    "title": "Trees",
    "section": "Quadratic",
    "text": "Quadratic\nHow about a quadratic effect? This data has distortion, but I don’t think it is overwhelmingly obvious. This time I fit two linear regression, one which models the true effect & another that does not, and a gradient boosted tree.\n\nd['Y'] = 10 + d['X1']*-10 + (d['X2']**2)*2 + d['X3']*10 + f(0, 1, d.shape[0])\npx.scatter(d, x='X2', y='Y', title='Quadratic Effect: Simulated X & derived Y').show()\n\n                                                \n\n\nAs expected, the linear regression that ignores the quadratic effects misses entirely. The gradient boosted tree recovers the effect! Nice.\n\nlr_unmodeled = smf.ols(\"Y ~ X1 + X2 + X3\", data = d).fit()\nlr_modeled = smf.ols(\"Y ~ X1 + I(X2**2) + X3\", data = d).fit()\ngb = GradientBoostingRegressor(n_estimators=100).fit(d[features], d['Y'])\n\nnewdata = d[features].assign(X1 = lambda df: df['X1'].mean(), X3 = lambda df: df['X3'].mean())\nlr_un_preds = lr_unmodeled.predict(newdata); lr_m_preds = lr_modeled.predict(newdata); g_preds = gb.predict(newdata); rf_preds = rf.predict(newdata)\nnewdata['Linear Regression (not-modeled)'] = lr_un_preds; newdata['Linear Regression (modeled)'] = lr_m_preds; newdata['Gradient Boosted Tree'] = g_preds\n\nfig = px.scatter(\n    newdata,\n    x='X2', \n    y=['Linear Regression (not-modeled)','Linear Regression (modeled)', 'Gradient Boosted Tree'],\n    title='Fitted Values @ X2'\n)\nfig.update_layout(yaxis_title=\"Fitted Value\")\nfig.show()"
  },
  {
    "objectID": "posts/trees/index.html#non-linear",
    "href": "posts/trees/index.html#non-linear",
    "title": "Trees",
    "section": "Non-Linear",
    "text": "Non-Linear\nWhat about a nonlinear effect? Same process as before. Our effect of interest is better hidden this time.\n\nd['Y'] = 10 + d['X1']*-20 + 2*np.exp(0.90 * d['X2']) + d['X3']*10 + f(0, 1, d.shape[0])\npx.scatter(d, x='X2', y='Y', title='Non-Linear Effect: Simulated X & derived Y').show()\n\n                                                \n\n\nAgain the gradient boosted machine recovers the effect. Nice again.\n\nlr_unmodeled = smf.ols(\"Y ~ X1 + X2 + X3\", data = d).fit()\nlr_modeled = smf.ols(\"Y ~ X1 + I(2*np.exp(0.75 * X2)) + X3\", data = d).fit()\ngb = GradientBoostingRegressor(n_estimators=100).fit(d[features], d['Y'])\n\nnewdata = d[features].assign(X1 = lambda df: df['X1'].mean(), X3 = lambda df: df['X3'].mean())\nlr_un_preds = lr_unmodeled.predict(newdata); lr_m_preds = lr_modeled.predict(newdata); g_preds = gb.predict(newdata); rf_preds = rf.predict(newdata)\nnewdata['Linear Regression (not-modeled)'] = lr_un_preds; newdata['Linear Regression (modeled)'] = lr_m_preds; newdata['Gradient Boosted Tree'] = g_preds\n\nfig = px.scatter(\n    newdata,\n    x='X2', \n    y=['Linear Regression (not-modeled)','Linear Regression (modeled)', 'Gradient Boosted Tree'],\n    title='Fitted Values @ X2'\n)\nfig.update_layout(yaxis_title=\"Fitted Value\")\nfig.show()"
  },
  {
    "objectID": "posts/trees/index.html#interaction",
    "href": "posts/trees/index.html#interaction",
    "title": "Trees",
    "section": "Interaction",
    "text": "Interaction\nWhat about an unstated interaction? Not sure I formatted this one correct, but the output of the linear regression with the effect modeled & the gradient boosted tree are more similar than the non-modeled LR.\n\nd['X1_X3'] = d['X1']*d['X3']\nd['Y'] = 10 + d['X1']*-10 + d['X2']*50 + d['X3']*10 + (d['X1_X3'])*5 + f(0, 1, d.shape[0])\npx.scatter(d, x='X1_X3', y='Y', title='Non-Linear Effect: Simulated X & derived Y').show()\n\n                                                \n\n\n\nlr_unmodeled = smf.ols(\"Y ~ X1 + X2 + X3\", data = d).fit()\nlr_modeled = smf.ols(\"Y ~ X1 + X2 + X3 + X1:X3\", data = d).fit()\ngb = GradientBoostingRegressor(n_estimators=100).fit(d[features], d['Y'])\n\nnewdata = d[features].assign(X2 = lambda df: df['X2'].mean())\nlr_un_preds = lr_unmodeled.predict(newdata); lr_m_preds = lr_modeled.predict(newdata); g_preds = gb.predict(newdata); rf_preds = rf.predict(newdata)\nnewdata['Linear Regression (not-modeled)'] = lr_un_preds; newdata['Linear Regression (modeled)'] = lr_m_preds; newdata['Gradient Boosted Tree'] = g_preds\n\nfig = px.scatter(\n    newdata.assign(X1_X3=lambda df: df['X1'] * df['X3']),\n    x='X1_X3', \n    y=['Linear Regression (not-modeled)','Linear Regression (modeled)', 'Gradient Boosted Tree'],\n    title='Fitted Values @ X1:X3'\n)\nfig.update_layout(yaxis_title=\"Fitted Value\")\nfig.show()"
  },
  {
    "objectID": "posts/rainwater/index.html",
    "href": "posts/rainwater/index.html",
    "title": "Rainwater’s Property Tax Plan",
    "section": "",
    "text": "A few weeks ago, Ethan Hatcher mention on twitter that he would be interviewing Donald Rainwater, the Libertarian candidate for Governor of Indiana.\nSome of the folks at WIBC, Ethan & Rob in particular, are ardently advocating for property tax reform. Rainwater has a made tax reduction his top issue; the first listed on his campaign site.\nHere’s his Property Tax policy:\nIt’s very simple. The property tax will be 1% of the sale price each year. After 7% has been paid (7 years of payments) no more tax will be due.\nHatcher & I often go back and forth on Twitter. When he posted that Rainwater would be on his Saturday night show, I asked him to pose a question.\nWhat would be the impact of Rainwater’s property tax policy? How would it impact small Hoosier towns & would any cease to exist?\nHatcher told me he would ask Rainwater this, and he’s a man of his word:\nRainwater responds by saying we should have a “real, serious conversation” about where property taxes are being spent today. He mentions that we, the citizens, should knock on the door and ask to see a transparent accounting of how our tax dollars are being spent.\nHere is how Indiana property taxes are spent:\nI found this chart on this website.\nI was disappointed by Rainwater’s response. He seemed to not know that this information is publically available, or he’s just to lazy to do the work."
  },
  {
    "objectID": "posts/rainwater/index.html#footnotes",
    "href": "posts/rainwater/index.html#footnotes",
    "title": "Rainwater’s Property Tax Plan",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNo 2023 data for Owens, Franklin, and Vermillion↩︎"
  },
  {
    "objectID": "posts/NGBoost/index.html",
    "href": "posts/NGBoost/index.html",
    "title": "Survival & Ngboost",
    "section": "",
    "text": "I’m interested in tree-based models’ ability to estimate nonlinear effects & interactions not specified in the design matrix.\nBeing interested in effect measurement, in the way stats twitter is, seems to be similar to valuing predictive performance, like my prior positions at gambling start-ups were.\nThe model doesn’t matter. The ability to estimate the effect does. So why not use trees?\nA few years ago the Standford ML Group released NGBoost.\nThey describe it as:\n…\nWith this learned distribution, you can get the mean & stdev at a given value. Also, it allows you to model the joint distribution of two variables."
  },
  {
    "objectID": "posts/NGBoost/index.html#veterans",
    "href": "posts/NGBoost/index.html#veterans",
    "title": "Survival & Ngboost",
    "section": "Veterans",
    "text": "Veterans\nHere, I am using the veterans dataset. ngb.pred_dist returns a scipy.stats object, so it has the method .cdf()\n\nimport pandas as pd\nimport numpy as np\nfrom ngboost import NGBSurvival\nfrom ngboost.distns import LogNormal, Gamma, Laplace\nimport plotly.express as px\nimport warnings\nwarnings.filterwarnings('ignore')\n\nd = pd.read_csv('veteran.csv')\n\nX = d[['trt']].values\nT = d[['time']].values\nE = d[['status']].values\n\nngb = NGBSurvival(\n    Dist=LogNormal,\n    n_estimators=100).fit(X, T, E)\n\npreds = ngb.predict(X)\ndist = ngb.pred_dist([[1],[2]]) # treatment 1 & 2\n\nest_times = (\n    pd.DataFrame(\n        [np.concatenate([[t], dist.cdf(t)]) for t in range(0,250,2)],\n        columns=['time','trt1','trt2'])\n)\n\nfig = px.line(est_times, x='time', y=['trt1','trt2'])\nfig.show()\n\n[iter 0] loss=5.4733 val_loss=0.0000 scale=2.0000 norm=2.5423"
  },
  {
    "objectID": "posts/NGBoost/index.html#simulation",
    "href": "posts/NGBoost/index.html#simulation",
    "title": "Survival & Ngboost",
    "section": "Simulation",
    "text": "Simulation\nI’ve adapted this simulation code from PhDemetri.\n\nfrom numpy import exp as exp\nfrom scipy.stats import norm, binom, weibull_min, uniform\nfrom scipy.optimize import brentq\nfrom lifelines import CoxPHFitter\n\nnp.random.seed(0)\n\nN = 25000\nage = norm.rvs(size=N)\nsex = binom.rvs(1, 0.5, size=N)\nweight = norm.rvs(size=N)\nX = np.vstack([age,sex,weight]).T\nbeta = [1, 0.15, 0.325]\nxb = X @ beta\n\nfinv = lambda x, u, xb: (1 - weibull_min.cdf(x, c=4, scale=5))**(exp(xb)) - u\n\nfailure_times = np.zeros(N)\ncensor_times = np.zeros(N)\n\nfor i in range(N):\n  uu = uniform.rvs(size=1)\n  cc = uniform.rvs(size=1)\n  failure_times[i] = brentq(finv, 0, 20, args=(uu, xb[i]))\n  censor_times[i] = brentq(finv, 0, 20, args=(cc, xb[i]))\n\ntime = np.minimum(failure_times, censor_times)\nevent = 1*(failure_times&lt;censor_times)\n\nNext we fit the Cox Proportional Hazard model to the simulated data.\n\nmodel_data = pd.DataFrame({'time':time,'event':event,'age':age,'sex':sex,'weight':weight})\n\ncph = CoxPHFitter().fit(model_data, duration_col='time', event_col='event', formula=\"age + sex + weight\");\n\nThe true & estimated survival curves are overlapping. Nice.\n\nnewdata = pd.DataFrame({'age':0, 'sex':0,'weight':0}, index=[0])\n\npreds = (\n  cph.predict_survival_function(newdata)\n  .reset_index()\n  .rename(columns={'index':'time',0:'estimated'})\n  .assign(\n    estimated = lambda df: 1-df.estimated,\n    truth = lambda df: weibull_min.cdf(df.time, c=4, scale=5)\n  )\n)\n\nfig = px.scatter(\n  preds,\n  x = 'time',\n  y=['estimated','truth'],\n  title = 'Estimated Survival Time'\n)\nfig.show()\n\n                                                \n\n\nNGBoost doesn’t currently have an implementation of the Weibull Distribution. The current list of distributions can be found here.\nThough, the authors of the package provide an example of how to implement a distribution here.\n\nX = model_data[['age','sex','weight']].values\nT = model_data[['time']].values\nE = model_data[['event']].values\n\nngb = NGBSurvival(Dist=LogNormal, verbose_eval=40, n_estimators=300).fit(X, T, E)\n\n[iter 0] loss=1.3918 val_loss=0.0000 scale=2.0000 norm=1.6299\n[iter 40] loss=1.1910 val_loss=0.0000 scale=2.0000 norm=1.1058\n[iter 80] loss=1.1387 val_loss=0.0000 scale=2.0000 norm=1.0552\n[iter 120] loss=1.1178 val_loss=0.0000 scale=2.0000 norm=1.0576\n[iter 160] loss=1.1081 val_loss=0.0000 scale=2.0000 norm=1.0713\n[iter 200] loss=1.1032 val_loss=0.0000 scale=2.0000 norm=1.0859\n[iter 240] loss=1.1004 val_loss=0.0000 scale=2.0000 norm=1.0978\n[iter 280] loss=1.0982 val_loss=0.0000 scale=2.0000 norm=1.1059\n\n\n\ndist = ngb.pred_dist([[0,0,0],[0,1,0]])\n\nestimated = (\n    pd.DataFrame(\n        [np.concatenate([[t], dist.cdf(t)]) for t in np.linspace(0, 12, 100)],\n        columns=['time','estimated_s0','estimated_s1']\n    )\n)\n\nfig = px.line(estimated, x='time', y=['estimated_s0','estimated_s1'], title='NGBoost Survival Curves')\nfig.show()\n\n                                                \n\n\nNGBoost’s estimated values are derived from a different distribution, but they look good nonetheless.\n\ndist = ngb.pred_dist([[0,0,0]])\npreds['ngboost (lognormal)'] = dist.cdf(preds['time'].values.reshape(-1,1)).ravel()\n\npx.scatter(\n  preds,\n  x = 'time',\n  y=['ngboost (lognormal)','estimated','truth'],\n  title = 'Estimated Survival Time'\n).show()"
  },
  {
    "objectID": "posts/indy/index.html",
    "href": "posts/indy/index.html",
    "title": "Indianapolis: Crime Downtown",
    "section": "",
    "text": "Indianapolis is smack dab in the middle of Indiana, which is a conservative state. Therefore, conservative talk radio is abundant. One of my guilty pleasures is conservative talk radio. I can’t count the number of times my father had Rush Limbaugh on in the car. The radioman was an additional, parasocial crazy uncle. I have always had some form of conservative media in my life. Hearing old men gasp at the latest liberal cultural transgression makes me feel nostologic & at home.\nIf you were to take these guys1 seriously, you’d think Indianapolis was a war zone. It is true that Indianapolis has a lot of violence, so their warnings are not totally without merit. But when I hear them talk about the violence in Indianapolis, I think of downtown.\nI’ve lived in downtown Indianapolis for three years. I have never felt in danger. So, what gives? Maybe it’s that I am a large dude (I’ve lost some weight since my playing days I swear). My wife does feel uncomfortable “near the circle”. I’ve heard her mother, an Irvington resident, say similar things.\nIs downtown actually dangerous?\nI am going to only consider Violent Crime, which in this dataset falls into one of these Categories: Homicide, Robbery, Assault, or Sexual Offense.\nIMPD releases crime data with coordinates. This is the 2021 UCR data. Let’s check it out."
  },
  {
    "objectID": "posts/indy/index.html#footnotes",
    "href": "posts/indy/index.html#footnotes",
    "title": "Indianapolis: Crime Downtown",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTony Kats, Robert Evans, & Tony Kinnett↩︎\ncorrection: initally read 10x10, credit to josiah for this correction↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "Title\n\n\nCategories\n\n\nDate\n\n\n\n\n\n\nRainwater’s Property Tax Plan\n\n\npost\n\n\nJul 3, 2024\n\n\n\n\nSurvival & Ngboost\n\n\ncode, survival\n\n\nFeb 14, 2024\n\n\n\n\nTrees\n\n\npost, statistics\n\n\nFeb 10, 2024\n\n\n\n\nConsumer Sentiment\n\n\npost, economics, vibe-cession\n\n\nJan 24, 2024\n\n\n\n\nMultiple Virtual Environments\n\n\npost, quarto\n\n\nJan 20, 2024\n\n\n\n\nIndianapolis: Crime Downtown\n\n\npost\n\n\nJan 13, 2024\n\n\n\n\npipeline\n\n\ncode, sklearn, Pipeline\n\n\nDec 27, 2023\n\n\n\n\npandas\n\n\ncode, dates, timeseries\n\n\nDec 20, 2023\n\n\n\n\nLLM\n\n\ncode, LLM\n\n\nDec 16, 2023\n\n\n\n\ndocker\n\n\ncode, analysis\n\n\nDec 2, 2023\n\n\n\n\nairflow\n\n\ncode\n\n\nDec 2, 2023\n\n\n\n\n\nNo matching items"
  }
]